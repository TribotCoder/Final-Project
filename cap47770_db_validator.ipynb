{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75346191",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05abff4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's reconnect to the database\n",
    "try:\n",
    "    import mysql.connector as sql\n",
    "    conn = sql.connect(\n",
    "        host='localhost', \n",
    "        user='root', \n",
    "        password='cap4770',\n",
    "        database= 'cap4770',  \n",
    "        use_pure = True)\n",
    "    \n",
    "    cursor = conn.cursor(buffered=True)\n",
    "    cursor.execute(\"use cap4770\")\n",
    "    print(\"Connected to database established.\")\n",
    "    # Check what tables are available\n",
    "    cursor.execute(\"show tables\")\n",
    "    tables = cursor.fetchall()\n",
    "    print(\"Available tables:\")\n",
    "    for table in tables:\n",
    "        print(f\"- {table[0]}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Database connection error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d827ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count records in the storm events CSV file\n",
    "storm_df = pd.read_csv('StormEvents_details-ftp_v1.0_d2011_c20250520.csv')\n",
    "csv_record_count = len(storm_df)\n",
    "print(f\"Total records in CSV file: {csv_record_count:,}\")\n",
    "print(f\"CSV file shape: {storm_df.shape}\")\n",
    "print(f\"Columns: {storm_df.shape[1]}, Rows: {storm_df.shape[0]}\")\n",
    "\n",
    "# Compare with database count\n",
    "if 'storm_table_name' in locals() and storm_table_name:\n",
    "    try:\n",
    "        cursor.execute(f\"SELECT COUNT(*) FROM {storm_table_name}\")\n",
    "        db_record_count = cursor.fetchone()[0]\n",
    "        print(f\"\\nDatabase table '{storm_table_name}' records: {db_record_count:,}\")\n",
    "        print(f\"Records match: {csv_record_count == db_record_count}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting database count: {e}\")\n",
    "else:\n",
    "    print(\"\\nDatabase connection not available for comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f750b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install SQLAlchemy for efficient database uploads\n",
    "!pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27194ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload all CSV records to database\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "try:\n",
    "    # Create SQLAlchemy engine for better pandas integration\n",
    "    engine = create_engine(f\"mysql+mysqlconnector://root:cap4770@localhost/cap4770\")\n",
    "    \n",
    "    # Read the full CSV file\n",
    "    print(\"Reading full CSV file...\")\n",
    "    storm_df_full = pd.read_csv('StormEvents_details-ftp_v1.0_d2011_c20250520.csv')\n",
    "    print(f\"CSV records loaded: {len(storm_df_full):,}\")\n",
    "    \n",
    "    # Option 1: Replace the entire table with all CSV data\n",
    "    print(\"\\nUploading all records to database...\")\n",
    "    print(\"This may take a few minutes...\")\n",
    "    \n",
    "    # Upload to database (replace existing table)\n",
    "    storm_df_full.to_sql('StormEvents_details', con=engine, if_exists='replace', index=False, chunksize=1000)\n",
    "    \n",
    "    print(\"Upload completed!\")\n",
    "    \n",
    "    # Verify the upload\n",
    "    cursor.execute(f\"SELECT COUNT(*) FROM StormEvents_details\")\n",
    "    new_db_count = cursor.fetchone()[0]\n",
    "    print(f\"New database record count: {new_db_count:,}\")\n",
    "    print(f\"Upload successful: {new_db_count == len(storm_df_full)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error during upload: {e}\")\n",
    "    print(\"You may need to install sqlalchemy: pip install sqlalchemy\")\n",
    "    \n",
    "    # Alternative approach using direct MySQL connector (slower but doesn't require SQLAlchemy)\n",
    "    print(\"\\nTrying alternative upload method...\")\n",
    "    try:\n",
    "        # Clear existing table first\n",
    "        cursor.execute(\"DELETE FROM StormEvents_details\")\n",
    "        conn.commit()\n",
    "        \n",
    "        # Prepare insert statement\n",
    "        columns = storm_df_full.columns.tolist()\n",
    "        placeholders = ', '.join(['%s'] * len(columns))\n",
    "        insert_query = f\"INSERT INTO StormEvents_details ({', '.join(columns)}) VALUES ({placeholders})\"\n",
    "        \n",
    "        # Insert data in chunks\n",
    "        chunk_size = 1000\n",
    "        total_rows = len(storm_df_full)\n",
    "        \n",
    "        for i in range(0, total_rows, chunk_size):\n",
    "            chunk = storm_df_full.iloc[i:i+chunk_size]\n",
    "            data_tuples = [tuple(row) for row in chunk.values]\n",
    "            cursor.executemany(insert_query, data_tuples)\n",
    "            conn.commit()\n",
    "            print(f\"Uploaded {min(i+chunk_size, total_rows)}/{total_rows} records...\")\n",
    "        \n",
    "        print(\"Alternative upload completed!\")\n",
    "        \n",
    "        # Verify\n",
    "        cursor.execute(f\"SELECT COUNT(*) FROM StormEvents_details\")\n",
    "        new_db_count = cursor.fetchone()[0]\n",
    "        print(f\"Final database record count: {new_db_count:,}\")\n",
    "        \n",
    "    except Exception as e2:\n",
    "        print(f\"Alternative upload also failed: {e2}\")\n",
    "        print(\"Manual database upload may be required.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd213f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that all records are now in the database\n",
    "print(\"=== UPLOAD VERIFICATION ===\")\n",
    "\n",
    "# Get current counts\n",
    "csv_count = len(pd.read_csv('StormEvents_details-ftp_v1.0_d2011_c20250520.csv'))\n",
    "cursor.execute(f\"SELECT COUNT(*) FROM StormEvents_details\")\n",
    "db_count = cursor.fetchone()[0]\n",
    "\n",
    "print(f\"CSV file records: {csv_count:,}\")\n",
    "print(f\"Database records: {db_count:,}\")\n",
    "print(f\"Records match: {csv_count == db_count}\")\n",
    "\n",
    "if csv_count == db_count:\n",
    "    print(\"\\n✅ SUCCESS: All CSV records have been uploaded to the database!\")\n",
    "    print(\"Your damage analysis will now use the complete dataset of 79,091 records.\")\n",
    "else:\n",
    "    print(f\"\\n❌ WARNING: Record count mismatch!\")\n",
    "    print(f\"Missing records: {csv_count - db_count:,}\")\n",
    "\n",
    "# Show some basic stats about the complete database\n",
    "print(f\"\\n=== DATABASE STATISTICS ===\")\n",
    "cursor.execute(\"SELECT COUNT(DISTINCT event_type) FROM StormEvents_details\")\n",
    "event_types = cursor.fetchone()[0]\n",
    "print(f\"Total unique event types: {event_types}\")\n",
    "\n",
    "cursor.execute(\"SELECT MIN(BEGIN_DATE_TIME), MAX(BEGIN_DATE_TIME) FROM StormEvents_details\")\n",
    "date_range = cursor.fetchone()\n",
    "print(f\"Date range: {date_range[0]} to {date_range[1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
